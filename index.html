<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Jose Luis Ponton </title> <meta name="author" content="Jose Luis Ponton"> <meta name="description" content="Jose Luis Ponton Portfolio"> <meta name="keywords" content="Jose Luis, Ponton, Portfolio, Animation, Deep Learning, Computer Graphics, Virtual Reality, Mixed Reality, VR, MR, AR# add your own keywords or leave empty"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joseluisponton.com/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6A%6F%73%65.%6C%75%69%73.%70%6F%6E%74%6F%6E@%75%70%63.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/JLPM22" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/jlponton" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0001-6576-4528" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://www.researchgate.net/profile/Jose-Luis-Ponton/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://scholar.google.com/citations?user=yNa9qSIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv_joseluis_ponton.pdf">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Jose Luis</span> Ponton </h1> <p class="desc"><a href="https://www.upc.edu/en" rel="external nofollow noopener" target="_blank">UPC</a>. Character Animation. Machine Learning. Computer Graphics. XR.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?3092f7ca5fe03aacacd3986d99d164c0" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hello! I am a Ph.D. student at <a href="https://www.upc.edu/en" rel="external nofollow noopener" target="_blank">Universitat Politècnica de Catalunya</a> in Barcelona (Spain), working at the <a href="https://www.virvig.eu/" rel="external nofollow noopener" target="_blank">ViRVIG</a> research group.</p> <p>My research interests are <strong>character animation</strong>, <strong>virtual and augmented reality</strong>, <strong>deep learning</strong> and <strong>computer graphics</strong>.</p> <p>Currently, I am working in <strong>data-driven character animation</strong>, in particular, motion understanding and synthesis, motion matching, retargeting, inverse kinematics, motion capture and virtual reality avatars.</p> <p>I received my M.Sc. in Computer Graphics and B.S. in Computer Science at <a href="https://www.upc.edu/en" rel="external nofollow noopener" target="_blank">Universitat Politècnica de Catalunya</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 13, 2025</th> <td> Our paper <a href="/assets/pdf/dragposer_EG2025.pdf">DragPoser</a> was accepted at <a href="https://eg25.cs.ucl.ac.uk/" rel="external nofollow noopener" target="_blank">Eurographics 2025</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> I am starting an internship at <a href="https://www.via-center.science/" rel="external nofollow noopener" target="_blank">Max Planck Institute for Informatics</a> under the supervision of <a href="https://people.mpi-inf.mpg.de/~theobalt/" rel="external nofollow noopener" target="_blank">Prof. Dr. Christian Theobalt</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 30, 2024</th> <td> I’ve joined the core R&amp;D team at <a href="https://hyper.online/" rel="external nofollow noopener" target="_blank">Hyper Online</a>, a YCombinator and Amazon-backed startup, as an external contractor to continue developing virtual avatars for VTubers. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 01, 2024</th> <td> Our paper <a href="/assets/pdf/stretchyourreach_chi24.pdf">Stretch Your Reach</a> was accepted at the <a href="https://chi2024.acm.org/" rel="external nofollow noopener" target="_blank">CHI ‘24 conference on Human Factors in Computing Systems</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 16, 2024</th> <td> Our paper <a href="/assets/pdf/expectedcollisionfeedback_ieeevr24.pdf">Exploring the role of expected collision feedback in VR</a> was accepted at the <a href="https://ieeevr.org/2024/" rel="external nofollow noopener" target="_blank">31st IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR 2024)</a>. </td> </tr> </table> </div> </div> <div style="margin-bottom: 20px;"></div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/dragposer.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dragposer.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2025:ponton:dragposer" class="col-sm-8"> <div class="title">DragPoser: Motion Reconstruction from Variable Sparse Tracking Signals via Latent Space Optimization</div> <div class="author"> <em>Jose Luis Ponton</em>, Eduard Pujol, <a href="http://andreasaristidou.com/" rel="external nofollow noopener" target="_blank">Andreas Aristidou</a>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <em>In Eurographics 2025</em> <div class="periodical"> <em>Computer Graphics Forum</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1111/cgf.70026" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/dragposer_EG2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/vyboiIBe0kc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/DragPoser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://upc-virvig.github.io/DragPoser/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>We introduce DragPoser, a novel deep-learning-based motion reconstruction system that accurately represents hard and dynamic constraints, attaining real-time high end-effectors position accuracy. This is achieved through a pose optimization process within a structured latent space. Our system requires only one-time training on a large human motion dataset, and then constraints can be dynamically defined as losses, while the pose is iteratively refined by computing the gradients of these losses within the latent space.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">2025:ponton:dragposer</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Pujol, Eduard and Aristidou, Andreas and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DragPoser: Motion Reconstruction from Variable Sparse Tracking Signals via Latent Space Optimization}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Eurographics 2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{n/a}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{n/a}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{e70026}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/cgf.70026}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/stretchyourreach.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="stretchyourreach.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2024:ponton:stretchyourreach" class="col-sm-8"> <div class="title">Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction</div> <div class="author"> <em>Jose Luis Ponton</em>, Reza Keshavarz, Alejandro Beacco, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In Proceedings of the CHI Conference on Human Factors in Computing Systems</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3613904.3642268" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/stretchyourreach_chi24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/e1-LuHWDjLU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In VR, misalignment between the user’s body and their virtual avatar can disrupt the sense of embodiment and hinder interaction. This study examines five different interaction modes, manipulating factors like virtual controller visibility and hand positioning. The results reveal that "stretching" the avatar’s arms to align with the user’s hands significantly improves embodiment, proprioception, user preference, and task performance. Interestingly, whether the virtual controllers are rendered or not had no significant impact.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">2024:ponton:stretchyourreach</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Keshavarz, Reza and Beacco, Alejandro and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400703300}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3613904.3642268}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{109}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/sparseposer.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sparseposer.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2023:ponton:sparseposer" class="col-sm-8"> <div class="title">SparsePoser: Real-Time Full-Body Motion Reconstruction from Sparse Data</div> <div class="author"> <em>Jose Luis Ponton</em>, <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <a href="http://andreasaristidou.com/" rel="external nofollow noopener" target="_blank">Andreas Aristidou</a>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <em>In SIGGRAPH Asia 2023</em> <div class="periodical"> <em>ACM Trans. Graph.</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3625264" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/sparseposer_siggraphasia2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/BAi4KoHtehY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/SparsePoser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://upc-virvig.github.io/SparsePoser/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>SparsePoser is a novel deep learning-based approach for reconstructing full-body human motion in VR using a reduced set of six tracking devices. By learning the human motion manifold from motion capture data and incorporating a learned IK component, it overcomes the limitations of traditional IK methods and IMU-based approaches, producing high-quality, continuous poses. Our extensive evaluations on motion capture datasets and real-time demos demonstrate that SparsePoser outperforms state-of-the-art techniques and can be applied to users with varying body dimensions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">2023:ponton:sparseposer</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Yun, Haoran and Aristidou, Andreas and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SparsePoser: Real-Time Full-Body Motion Reconstruction from Sparse Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{February 2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{SIGGRAPH Asia 2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{43}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0730-0301}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3625264}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Trans. Graph.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/fittedavatars.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fittedavatars.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2023:ponton:fittedavatars" class="col-sm-8"> <div class="title">Fitted avatars: automatic skeleton adjustment for self-avatars in virtual reality</div> <div class="author"> <em>Jose Luis Ponton</em>, Victor Ceballos, Lesly Acosta, <a href="https://www.cs.upc.edu/~arios/" rel="external nofollow noopener" target="_blank">Alejandro Rios</a>, Eva Monclus, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>Virtual Reality</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10055-023-00821-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/fittedavatars_vr2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/U7KOhTGByyc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Self-avatars are essential for enhancing presence and communication in VR. However, ensuring accurate dimensions often requires manual measurements, which can be time-consuming and error-prone. This paper proposes an automatic method using a head-mounted display (HMD), hand controllers, and trackers to accurately estimate user measurements and adjust the virtual skeleton. This method improves the alignment of the avatar with the user’s body, surpassing solutions that rely on uniform scaling or assumptions about joint locations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">2023:ponton:fittedavatars</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fitted avatars: automatic skeleton adjustment for self-avatars in virtual reality}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Ceballos, Victor and Acosta, Lesly and Rios, Alejandro and Monclus, Eva and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Virtual Reality}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2541--2560}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1434-9957}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10055-023-00821-z}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/animationfidelity.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="animationfidelity.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2023:yun:animationfidelity" class="col-sm-8"> <div class="title">Animation Fidelity in Self-Avatars: Impact on User Performance and Sense of Agency</div> <div class="author"> <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <em>Jose Luis Ponton</em>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In 2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)</em>, Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VR55154.2023.00044" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/animation_fidelity_ieeevr23.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/X1POhdDIvm0?si=SnPHPOAxrmu3lERO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>This research investigates the impact of avatar animation fidelity on various tasks in VR. Comparing three animation techniques (two using Inverse Kinematics and one using a motion capture system), the study found that the quality of animation influences the user’s sense of embodiment. Surprisingly, IK-based solutions, despite using fewer sensors, sometimes outperformed MoCap in tasks requiring precise positioning due to lower latency and less positional drift.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">2023:yun:animationfidelity</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Animation Fidelity in Self-Avatars: Impact on User Performance and Sense of Agency}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yun, Haoran and Ponton, Jose Luis and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{IEEE}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{286-296}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2642-5254}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/VR55154.2023.00044}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/mmvr.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mmvr.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2022:ponton:mmvr" class="col-sm-8"> <div class="title">Combining Motion Matching and Orientation Prediction to Animate Avatars for Consumer-Grade VR Devices</div> <div class="author"> <em>Jose Luis Ponton</em>, <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <em>In ACM SIGGRAPH / Eurographics Symposium on Computer Animation</em> <div class="periodical"> <em>Computer Graphics Forum</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1111/cgf.14628" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mmvr_sca2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/crU9oLX0GnM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/MMVR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://upc-virvig.github.io/MMVR/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Current VR avatar animation methods suffer from inaccurate lower body movement due to the limited tracking data available from consumer-grade devices. This paper presents a novel approach that utilizes a neural network to estimate user body orientation from HMD and controller inputs. By combining this orientation data with HMD velocity and rotation, a feature vector is generated to drive a motion matching algorithm. Tested on a MoCap database of VR users, this system produces a wider range of lower body animations that precisely match user orientation, enabling more realistic and diverse movement representation in VR.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">2022:ponton:mmvr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Yun, Haoran and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Combining Motion Matching and Orientation Prediction to Animate Avatars for Consumer-Grade VR Devices}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM SIGGRAPH / Eurographics Symposium on Computer Animation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{41}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107-118}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1467-8659}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1111/cgf.14628}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/avatargo.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="avatargo.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2022:ponton:avatargo" class="col-sm-8"> <div class="title">AvatarGo: Plug and Play self-avatars for VR</div> <div class="author"> <em>Jose Luis Ponton</em>, Eva Monclus, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In Eurographics 2022 - Short Papers</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.2312/egs.20221037" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/avatarGo_shortEG2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/DWU4p-a-uXo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/AvatarGo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Self-avatars in VR can greatly enhance user experience, especially in collaborative settings. Current methods for animating avatars can lead to mismatches between the user’s movement and the avatar’s. This paper introduces a simple but effective technique for calculating precise offsets for each user, resulting in significantly improved avatar movement and a stronger sense of embodiment.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">2022:ponton:avatargo</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Eurographics 2022 - Short Papers}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{AvatarGo: Plug and Play self-avatars for VR}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Monclus, Eva and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1017-4656}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-169-4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/egs.20221037}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Jose Luis Ponton. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-MM0JZRGDZ0"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-MM0JZRGDZ0');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>