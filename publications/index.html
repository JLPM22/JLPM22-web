<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Jose Luis Ponton </title> <meta name="author" content="Jose Luis Ponton"> <meta name="description" content="Jose Luis Ponton Portfolio"> <meta name="keywords" content="Jose Luis, Ponton, Portfolio, Animation, Deep Learning, Computer Graphics, Virtual Reality, Mixed Reality, VR, MR, AR# add your own keywords or leave empty"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joseluisponton.com/publications/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jose Luis</span> Ponton </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv_joseluis_ponton.pdf">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/stretchyourreach-480.webp 480w,/assets/img/publication_preview/stretchyourreach-800.webp 800w,/assets/img/publication_preview/stretchyourreach-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/stretchyourreach.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="stretchyourreach.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ponton2024stretchyourreach" class="col-sm-8"> <div class="title">Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction</div> <div class="author"> <em>Jose Luis Ponton</em>, Reza Keshavarz, Alejandro Beacco, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In Proceedings of the CHI Conference on Human Factors in Computing Systems</em> , May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/stretchyourreach_chi24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/e1-LuHWDjLU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>In VR, misalignment between the user’s body and their virtual avatar can disrupt the sense of embodiment and hinder interaction. This study examines five different interaction modes, manipulating factors like virtual controller visibility and hand positioning. The results reveal that "stretching" the avatar’s arms to align with the user’s hands significantly improves embodiment, proprioception, user preference, and task performance. Interestingly, whether the virtual controllers are rendered or not had no significant impact.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ponton2024stretchyourreach</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Keshavarz, Reza and Beacco, Alejandro and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400703300}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3613904.3642268}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3613904.3642268}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{109}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/expectedcollision-480.webp 480w,/assets/img/publication_preview/expectedcollision-800.webp 800w,/assets/img/publication_preview/expectedcollision-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/expectedcollision.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="expectedcollision.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10494178" class="col-sm-8"> <div class="title">Exploring the Role of Expected Collision Feedback in Crowded Virtual Environments</div> <div class="author"> <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <em>Jose Luis Ponton</em>, Alejandro Beacco, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In 2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)</em> , Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/expectedcollisionfeedback_ieeevr24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/DoG37fthIZE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>This study investigates the impact of expected collision feedback on user perception and interaction in virtual environments populated with virtual humans. We examine common feedback techniques (auditory, tactile) and the effect of inducing the expectation of a physical collision with a real person. Results indicate that expected collision feedback significantly influences both global navigation and local movements, as well as subjective perceptions of presence and copresence.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10494178</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yun, Haoran and Ponton, Jose Luis and Beacco, Alejandro and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring the Role of Expected Collision Feedback in Crowded Virtual Environments}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{472-481}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{IEEE}}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/VR58804.2024.00068}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/padelvic-480.webp 480w,/assets/img/publication_preview/padelvic-800.webp 800w,/assets/img/publication_preview/padelvic-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/padelvic.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="padelvic.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mohammadreza2024padelvic" class="col-sm-8"> <div class="title">PADELVIC: Multicamera Videos and Motion Capture Data in Padel Matches</div> <div class="author"> Javadiha Mohammadreza, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, Michele Calvanese, Enrique Lacasa, Jordi Moyes, <em>Jose Luis Ponton</em>, Antonio Susin, and Jiabo Wang </div> <div class="periodical"> <em>Padel Scientific Journal</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/padelvic_padel24.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/UPC-ViRVIG/PadelVic" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>PadelVic is an annotated dataset of an amateur padel match, featuring multi-view video streams, estimated positional data for all players, and motion capture data for one player. It also includes synthetic videos for training neural networks to estimate positional data. With its high accuracy, especially in the synthetic dataset, PadelVic is a valuable tool for researchers interested in automatic sports video analysis, player tracking, and tactical analysis.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">mohammadreza2024padelvic</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mohammadreza, Javadiha and Andujar, Carlos and Calvanese, Michele and Lacasa, Enrique and Moyes, Jordi and Ponton, Jose Luis and Susin, Antonio and Wang, Jiabo}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{PADELVIC: Multicamera Videos and Motion Capture Data in Padel Matches}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Padel Scientific Journal}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{89--106}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.17398/2952-2218.2.89}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/sparseposer-480.webp 480w,/assets/img/publication_preview/sparseposer-800.webp 800w,/assets/img/publication_preview/sparseposer-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/sparseposer.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sparseposer.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ponton2023sparseposer" class="col-sm-8"> <div class="title">SparsePoser: Real-Time Full-Body Motion Reconstruction from Sparse Data</div> <div class="author"> <em>Jose Luis Ponton</em>, <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <a href="http://andreasaristidou.com/" rel="external nofollow noopener" target="_blank">Andreas Aristidou</a>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <em>In SIGGRAPH Asia 2023</em> <div class="periodical"> <em>ACM Trans. Graph.</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/sparseposer_siggraphasia2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/BAi4KoHtehY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/SparsePoser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://upc-virvig.github.io/SparsePoser/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>SparsePoser is a novel deep learning-based approach for reconstructing full-body human motion in VR using a reduced set of six tracking devices. By learning the human motion manifold from motion capture data and incorporating a learned IK component, it overcomes the limitations of traditional IK methods and IMU-based approaches, producing high-quality, continuous poses. Our extensive evaluations on motion capture datasets and real-time demos demonstrate that SparsePoser outperforms state-of-the-art techniques and can be applied to users with varying body dimensions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ponton2023sparseposer</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Yun, Haoran and Aristidou, Andreas and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SparsePoser: Real-Time Full-Body Motion Reconstruction from Sparse Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{February 2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{SIGGRAPH Asia 2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{43}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0730-0301}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3625264}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3625264}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Trans. Graph.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fittedavatars-480.webp 480w,/assets/img/publication_preview/fittedavatars-800.webp 800w,/assets/img/publication_preview/fittedavatars-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/fittedavatars.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fittedavatars.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ponton2023fittedavatars" class="col-sm-8"> <div class="title">Fitted avatars: automatic skeleton adjustment for self-avatars in virtual reality</div> <div class="author"> <em>Jose Luis Ponton</em>, Victor Ceballos, Lesly Acosta, <a href="https://www.cs.upc.edu/~arios/" rel="external nofollow noopener" target="_blank">Alejandro Rios</a>, Eva Monclus, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>Virtual Reality</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/fittedavatars_vr2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/U7KOhTGByyc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Self-avatars are essential for enhancing presence and communication in VR. However, ensuring accurate dimensions often requires manual measurements, which can be time-consuming and error-prone. This paper proposes an automatic method using a head-mounted display (HMD), hand controllers, and trackers to accurately estimate user measurements and adjust the virtual skeleton. This method improves the alignment of the avatar with the user’s body, surpassing solutions that rely on uniform scaling or assumptions about joint locations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ponton2023fittedavatars</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fitted avatars: automatic skeleton adjustment for self-avatars in virtual reality}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Ceballos, Victor and Acosta, Lesly and Rios, Alejandro and Monclus, Eva and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Virtual Reality}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2541--2560}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1434-9957}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10055-023-00821-z}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/animationfidelity-480.webp 480w,/assets/img/publication_preview/animationfidelity-800.webp 800w,/assets/img/publication_preview/animationfidelity-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/animationfidelity.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="animationfidelity.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yun2023animationfidelity" class="col-sm-8"> <div class="title">Animation Fidelity in Self-Avatars: Impact on User Performance and Sense of Agency</div> <div class="author"> <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <em>Jose Luis Ponton</em>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In 2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)</em> , Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/animation_fidelity_ieeevr23.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/X1POhdDIvm0?si=SnPHPOAxrmu3lERO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>This research investigates the impact of avatar animation fidelity on various tasks in VR. Comparing three animation techniques (two using Inverse Kinematics and one using a motion capture system), the study found that the quality of animation influences the user’s sense of embodiment. Surprisingly, IK-based solutions, despite using fewer sensors, sometimes outperformed MoCap in tasks requiring precise positioning due to lower latency and less positional drift.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">yun2023animationfidelity</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Animation Fidelity in Self-Avatars: Impact on User Performance and Sense of Agency}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yun, Haoran and Ponton, Jose Luis and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{IEEE}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{286-296}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2642-5254}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/VR55154.2023.00044}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mmvr-480.webp 480w,/assets/img/publication_preview/mmvr-800.webp 800w,/assets/img/publication_preview/mmvr-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/mmvr.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mmvr.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ponton2022mmvr" class="col-sm-8"> <div class="title">Combining Motion Matching and Orientation Prediction to Animate Avatars for Consumer-Grade VR Devices</div> <div class="author"> <em>Jose Luis Ponton</em>, <a href="https://haoranyun.com/" rel="external nofollow noopener" target="_blank">Haoran Yun</a>, <a href="https://www.cs.upc.edu/~virtual/home/index.html" rel="external nofollow noopener" target="_blank">Carlos Andujar</a>, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <em>In ACM SIGGRAPH / Eurographics Symposium on Computer Animation</em> <div class="periodical"> <em>Computer Graphics Forum</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mmvr_sca2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/crU9oLX0GnM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/MMVR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://upc-virvig.github.io/MMVR/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Current VR avatar animation methods suffer from inaccurate lower body movement due to the limited tracking data available from consumer-grade devices. This paper presents a novel approach that utilizes a neural network to estimate user body orientation from HMD and controller inputs. By combining this orientation data with HMD velocity and rotation, a feature vector is generated to drive a motion matching algorithm. Tested on a MoCap database of VR users, this system produces a wider range of lower body animations that precisely match user orientation, enabling more realistic and diverse movement representation in VR.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ponton2022mmvr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Yun, Haoran and Andujar, Carlos and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Combining Motion Matching and Orientation Prediction to Animate Avatars for Consumer-Grade VR Devices}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM SIGGRAPH / Eurographics Symposium on Computer Animation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{41}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107-118}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1467-8659}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1111/cgf.14628}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/avatargo-480.webp 480w,/assets/img/publication_preview/avatargo-800.webp 800w,/assets/img/publication_preview/avatargo-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/avatargo.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="avatargo.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ponton2022avatargo" class="col-sm-8"> <div class="title">AvatarGo: Plug and Play self-avatars for VR</div> <div class="author"> <em>Jose Luis Ponton</em>, Eva Monclus, and <a href="https://www.cs.upc.edu/~npelechano/" rel="external nofollow noopener" target="_blank">Nuria Pelechano</a> </div> <div class="periodical"> <em>In Eurographics 2022 - Short Papers</em> , May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/avatarGo_shortEG2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/DWU4p-a-uXo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/UPC-ViRVIG/AvatarGo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Self-avatars in VR can greatly enhance user experience, especially in collaborative settings. Current methods for animating avatars can lead to mismatches between the user’s movement and the avatar’s. This paper introduces a simple but effective technique for calculating precise offsets for each user, resulting in significantly improved avatar movement and a stronger sense of embodiment.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ponton2022avatargo</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Eurographics 2022 - Short Papers}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{AvatarGo: Plug and Play self-avatars for VR}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ponton, Jose Luis and Monclus, Eva and Pelechano, Nuria}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{The Eurographics Association}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1017-4656}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-03868-169-4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2312/egs.20221037}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Jose Luis Ponton. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-MM0JZRGDZ0"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MM0JZRGDZ0");</script> </body> </html>